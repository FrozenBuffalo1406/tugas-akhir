{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "073babe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wfdb\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense, Dropout, Layer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "494772e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prep_data(db_dir: Path, signal_length: int = 1024, records_to_process: list = None):\n",
    "    \"\"\"\n",
    "    Memuat data, normalisasi, mapping label, dan otomatis unduh.\n",
    "    (VERSI PERBAIKAN FINAL DENGAN LOGIKA AFIB YANG LEBIH KUAT)\n",
    "    \"\"\"\n",
    "    if not db_dir.is_dir():\n",
    "        print(f\"Direktori '{db_dir}' tidak ditemukan. Memulai unduhan...\")\n",
    "        try:\n",
    "            wfdb.dl_database('mitdb', dl_dir=dl_dir)\n",
    "            print(\"Unduhan selesai.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Gagal mengunduh database: {e}\")\n",
    "            return np.array([]), np.array([])\n",
    "\n",
    "    print(f\"Memulai proses data dari '{db_dir}'...\")\n",
    "    if records_to_process is None: records_to_process = wfdb.get_record_list('mitdb')\n",
    "    \n",
    "    X, y = [], []\n",
    "    label_map = {'N': 'Normal','L': 'Normal','R': 'Normal','V': 'PVC','E': 'PVC','A': 'Other','a': 'Other','J': 'Other','S': 'Other','F': 'Other','/': 'Other','f': 'Other','Q': 'Other'}\n",
    "    \n",
    "    for rec_name in records_to_process:\n",
    "        print(f\"  -> Memproses record: {rec_name}\")\n",
    "        try:\n",
    "            record = wfdb.rdrecord(str(db_dir / rec_name))\n",
    "            annotation = wfdb.rdann(str(db_dir / rec_name), 'atr')\n",
    "            signal = record.p_signal[:, 1]\n",
    "            \n",
    "            rhythm_change_indices = np.where(annotation.symbol == '+')[0]\n",
    "            rhythm_events = {annotation.sample[i]: annotation.aux_note[i].strip('\\x00') for i in rhythm_change_indices}\n",
    "            rhythm_event_samples = sorted(rhythm_events.keys())\n",
    "\n",
    "            for i, loc in enumerate(annotation.sample):\n",
    "                symbol = annotation.symbol[i]\n",
    "                if symbol not in label_map: continue\n",
    "\n",
    "                current_rhythm = '(N'\n",
    "                for event_sample in rhythm_event_samples:\n",
    "                    if loc >= event_sample:\n",
    "                        current_rhythm = rhythm_events[event_sample]\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                final_label = ''\n",
    "                if '(AFIB' in current_rhythm:\n",
    "                    final_label = 'AF'\n",
    "                else:\n",
    "                    final_label = label_map.get(symbol)\n",
    "                \n",
    "                if final_label:\n",
    "                    half_len = signal_length // 2\n",
    "                    if loc > half_len and loc < len(signal) - half_len:\n",
    "                        segment = signal[loc - half_len : loc + half_len]\n",
    "                        if len(segment) == signal_length:\n",
    "                           segment = (segment - np.mean(segment)) / np.std(segment)\n",
    "                           X.append(segment)\n",
    "                           y.append(final_label)\n",
    "        except Exception as e:\n",
    "            print(f\"    Gagal memproses {rec_name}: {e}\")\n",
    "\n",
    "    print(\"Pemuatan dan persiapan data selesai.\")\n",
    "    if len(np.unique(y)) > 0: print(f\"Label yang berhasil diekstrak: {np.unique(y)}\")\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1baac150",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    \"\"\"Custom Attention Layer.\"\"\"\n",
    "    def __init__(self, **kwargs): super(Attention, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1), initializer=\"normal\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1), initializer=\"zeros\")\n",
    "        super(Attention, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        et = K.squeeze(K.tanh(K.dot(x, self.W) + self.b), axis=-1)\n",
    "        at = K.softmax(et)\n",
    "        at = K.expand_dims(at, axis=-1)\n",
    "        output = x * at\n",
    "        return K.sum(output, axis=1)\n",
    "    def compute_output_shape(self, input_shape): return (input_shape[0], input_shape[-1])\n",
    "\n",
    "def build_bilstm_attention_model(input_shape, num_classes):\n",
    "    \"\"\"Membangun model Keras dengan arsitektur Bi-LSTM + Attention + Dense.\"\"\"\n",
    "    print(\"\\nMembangun model Klasifikasi Bi-LSTM Attention...\")\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(inputs)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Attention()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(\"Model Klasifikasi berhasil dibangun.\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b781560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai proses data dari 'mitdb'...\n",
      "  -> Memproses record: 100\n",
      "  -> Memproses record: 101\n",
      "  -> Memproses record: 102\n",
      "  -> Memproses record: 103\n",
      "  -> Memproses record: 104\n",
      "  -> Memproses record: 105\n",
      "  -> Memproses record: 106\n",
      "  -> Memproses record: 107\n",
      "  -> Memproses record: 108\n",
      "  -> Memproses record: 109\n",
      "  -> Memproses record: 111\n",
      "  -> Memproses record: 112\n",
      "  -> Memproses record: 113\n",
      "  -> Memproses record: 114\n",
      "  -> Memproses record: 115\n",
      "  -> Memproses record: 116\n",
      "  -> Memproses record: 117\n",
      "  -> Memproses record: 118\n",
      "  -> Memproses record: 119\n",
      "  -> Memproses record: 121\n",
      "  -> Memproses record: 122\n",
      "  -> Memproses record: 123\n",
      "  -> Memproses record: 124\n",
      "  -> Memproses record: 200\n",
      "  -> Memproses record: 201\n",
      "  -> Memproses record: 202\n",
      "  -> Memproses record: 203\n",
      "  -> Memproses record: 205\n",
      "  -> Memproses record: 207\n",
      "  -> Memproses record: 208\n",
      "  -> Memproses record: 209\n",
      "  -> Memproses record: 210\n",
      "  -> Memproses record: 212\n",
      "  -> Memproses record: 213\n",
      "  -> Memproses record: 214\n",
      "  -> Memproses record: 215\n",
      "  -> Memproses record: 217\n",
      "  -> Memproses record: 219\n",
      "  -> Memproses record: 220\n",
      "  -> Memproses record: 221\n",
      "  -> Memproses record: 222\n",
      "  -> Memproses record: 223\n",
      "  -> Memproses record: 228\n",
      "  -> Memproses record: 230\n",
      "  -> Memproses record: 231\n",
      "  -> Memproses record: 232\n",
      "  -> Memproses record: 233\n",
      "  -> Memproses record: 234\n",
      "Pemuatan dan persiapan data selesai.\n",
      "Label yang berhasil diekstrak: ['Normal' 'Other' 'PVC']\n",
      "\n",
      "Menyiapkan data untuk klasifikasi...\n",
      "Kelas ditemukan (3): ['Normal' 'Other' 'PVC']\n",
      "Ukuran Data Latih: (87262, 1024, 1)\n",
      "Ukuran Data Validasi: (21816, 1024, 1)\n",
      "\n",
      "Membangun model Klasifikasi Bi-LSTM Attention...\n",
      "Model Klasifikasi berhasil dibangun.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1024, 1)]         0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 1024, 128)        33792     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024, 128)         0         \n",
      "                                                                 \n",
      " attention (Attention)       (None, 128)               1152      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,395\n",
      "Trainable params: 43,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Melatih model Klasifikasi...\n",
      "Epoch 1/25\n",
      "  60/1364 [>.............................] - ETA: 17:32 - loss: 0.6781 - accuracy: 0.8193"
     ]
    }
   ],
   "source": [
    "#main\n",
    "if __name__ == '__main__':\n",
    "    SIGNAL_LENGTH = 1024\n",
    "    DB_DIR = Path('mitdb')\n",
    "\n",
    "    # Memanggil fungsi HANYA SATU KALI untuk memproses seluruh database\n",
    "    # Argumen `records_to_process` dikosongkan agar semua record diproses\n",
    "    X_data, y_labels = load_and_prep_data(\n",
    "        db_dir=DB_DIR, \n",
    "        signal_length=SIGNAL_LENGTH\n",
    "    )\n",
    "    \n",
    "    if X_data.shape[0] < 10:\n",
    "        print(\"Data yang berhasil dimuat tidak cukup untuk training. Proses berhenti.\")\n",
    "    else:\n",
    "        X_data = X_data[..., np.newaxis]\n",
    "        \n",
    "        print(\"\\nMenyiapkan data untuk klasifikasi...\")\n",
    "        le = LabelEncoder()\n",
    "        y_encoded = le.fit_transform(y_labels)\n",
    "        num_classes = len(le.classes_)\n",
    "        y_one_hot = to_categorical(y_encoded, num_classes=num_classes)\n",
    "        print(f\"Kelas ditemukan ({num_classes}): {le.classes_}\")\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_data, y_one_hot, test_size=0.2, random_state=42, stratify=np.argmax(y_one_hot, axis=1)\n",
    "        )\n",
    "        print(f\"Ukuran Data Latih: {X_train.shape}\")\n",
    "        print(f\"Ukuran Data Validasi: {X_val.shape}\")\n",
    "\n",
    "        classifier_model = build_bilstm_attention_model(\n",
    "            input_shape=(SIGNAL_LENGTH, 1), \n",
    "            num_classes=num_classes\n",
    "        )\n",
    "        classifier_model.summary()\n",
    "\n",
    "        model_checkpoint = ModelCheckpoint(\n",
    "            filepath='model_terbaik.keras',\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            verbose=1\n",
    "        )\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        print(\"\\nMelatih model Klasifikasi...\")\n",
    "        history = classifier_model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=25,\n",
    "            batch_size=64,\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=1,\n",
    "            callbacks=[early_stopping, model_checkpoint] \n",
    "        )\n",
    "        print(\"\\nPipeline klasifikasi selesai!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tugasAkhir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
